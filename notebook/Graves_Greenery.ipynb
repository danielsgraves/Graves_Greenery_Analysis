{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielsgraves/Graves_Greenery_Analysis/blob/main/notebook/Graves_Greenery.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtDF7HRceRt5"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielsgraves/Graves_Greenery_Analysis/blob/main/notebook/Graves_Greenery.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQ0R2eIOeRt6"
      },
      "source": [
        "# Graves' Greenery Dataset\n",
        "\n",
        "> Colab is pre-configured with a **custom** SQL cell magic (`%sqlite` / `%%sqlite`) that uses a local SQLite database file under `/outputs`.\n",
        ">\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CH3Ed7fJeRt6"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# --- CONFIG ---\n",
        "REPO_USER = \"danielsgraves\"\n",
        "REPO_NAME = \"Graves_Greenery_Analysis\"                 # repo folder name after clone\n",
        "DATA_DIR  = f\"/content/{REPO_NAME}/data\"               # CSVs live here\n",
        "DB_FILE   = f\"/content/{REPO_NAME}/outputs/graves_greenery.db\"  # SQLite DB file\n",
        "LOAD_FROM_CSV = True   # set False to keep existing DB tables between sessions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oz4TI3_JeRt7"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# --- SYNC REPO: clone if missing, else pull latest ---\n",
        "import os, subprocess\n",
        "\n",
        "def run(cmd):\n",
        "    p = subprocess.run(cmd, shell=True, text=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
        "    print(p.stdout)\n",
        "    if p.returncode != 0:\n",
        "        raise RuntimeError(f\"Command failed: {cmd}\")\n",
        "\n",
        "if not os.path.exists(f\"/content/{REPO_NAME}\"):\n",
        "    run(f\"git clone https://github.com/{REPO_USER}/{REPO_NAME}.git /content/{REPO_NAME}\")\n",
        "else:\n",
        "    os.chdir(f\"/content/{REPO_NAME}\")\n",
        "    run(\"git fetch --all --prune\")\n",
        "    run(\"git pull --rebase\")\n",
        "\n",
        "os.makedirs(f\"/content/{REPO_NAME}/outputs\", exist_ok=True)\n",
        "os.chdir(f\"/content/{REPO_NAME}\")\n",
        "print(\"Working dir:\", os.getcwd())\n",
        "run(\"ls -la\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2-ebF8feRt7"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# --- CUSTOM %%sqlite MAGIC (no external deps beyond stdlib + pandas) ---\n",
        "import sqlite3, pandas as pd\n",
        "from IPython.core.magic import register_line_cell_magic\n",
        "\n",
        "# single shared connection for this session\n",
        "_conn = sqlite3.connect(DB_FILE)\n",
        "\n",
        "@register_line_cell_magic\n",
        "def sqlite(line, cell=None):\n",
        "    \"\"\"\n",
        "    Usage:\n",
        "      %sqlite SELECT 1;\n",
        "      %%sqlite\n",
        "      SELECT * FROM dim_customers LIMIT 5;\n",
        "\n",
        "    Returns a pandas DataFrame. It will render once if not assigned; if you assign it\n",
        "    (e.g., df = %%sqlite ...), it will not auto-display.\n",
        "    \"\"\"\n",
        "    sql = line if cell is None else (line + \"\\n\" + cell)\n",
        "    df = pd.read_sql_query(sql, _conn)\n",
        "    return df\n",
        "\n",
        "print(\"Custom %sqlite / %%sqlite magic registered. DB:\", DB_FILE)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4jYjfYOeRt7"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# --- LOAD ALL CSVs INTO SQLITE TABLES (idempotent) ---\n",
        "import glob, os\n",
        "\n",
        "if LOAD_FROM_CSV or (not os.path.exists(DB_FILE)):\n",
        "    try:\n",
        "        _conn.close()\n",
        "    except Exception:\n",
        "        pass\n",
        "    _conn = sqlite3.connect(DB_FILE)\n",
        "\n",
        "    files = sorted(glob.glob(os.path.join(DATA_DIR, \"*.csv\")))\n",
        "    if not files:\n",
        "        print(f\"⚠️ No CSVs found in {DATA_DIR}\")\n",
        "    for path in files:\n",
        "        table = os.path.splitext(os.path.basename(path))[0]\n",
        "        df = pd.read_csv(path)\n",
        "        # mild normalization for safer SQL\n",
        "        df.columns = [c.strip().replace(\" \", \"_\") for c in df.columns]\n",
        "        df.to_sql(table, _conn, if_exists=\"replace\", index=False)\n",
        "        print(f\"Loaded {table} ({len(df):,} rows)\")\n",
        "\n",
        "# list tables\n",
        "%sqlite SELECT name AS table_name FROM sqlite_master WHERE type='table' ORDER BY name;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fu_xUe7UeRt7"
      },
      "source": [
        "## SQL Sandbox\n",
        "Use `%%sqlite` below to run queries directly against the local SQLite database."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMzU2hrLeRt7"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "%%sqlite\n",
        "SELECT *\n",
        "FROM  graves_greenery_full_denormalized\n",
        "LIMIT 5;"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8MSlGweeRt8"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# --- Helper: save any query result to /outputs as CSV ---\n",
        "def sql_to_csv(query: str, out_path: str):\n",
        "    df = pd.read_sql_query(query, _conn)\n",
        "    df.to_csv(out_path, index=False)\n",
        "    print(f\"Saved {len(df):,} rows → {out_path}\")\n",
        "\n",
        "# Example:\n",
        "# sql_to_csv(\"SELECT * FROM dim_plants LIMIT 100\", \"outputs/dim_plants_sample.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdtPGGV3eRt8"
      },
      "source": [
        "# Project Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1bQjSIjeRt8"
      },
      "source": [
        "# Problem Statement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBV26efoeRt8"
      },
      "source": [
        "# Data Cleaning and Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R93CKnh9eRt8"
      },
      "source": [
        "# Exploratory Data Analysis (EDA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x08b8qwIeRt8"
      },
      "source": [
        "# Solution and Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kE_o1nqfeRt8"
      },
      "source": [
        "# Recommendations and Next Steps"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}