{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸŒ¿ Graves Greenery â€” Colab SQL Template (DuckDB + `%%sql` + GitHub CSVs)\n",
        "\n",
        "A serverless SQL sandbox for the Graves Greenery project.\n",
        "\n",
        "- Loads CSVs from your GitHub repo (public)\n",
        "- Creates tables in a persistent DuckDB database\n",
        "- Enables `%%sql` magic for pretty outputs\n",
        "- Optional `%%mysql` magic to use MySQL syntax via SQLGlot"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1) Install packages"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install duckdb ipython-sql pandas duckdb-engine sqlalchemy sqlglot"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) Imports & load SQL magic"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, re, glob, subprocess, textwrap, pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "# Load the ipython-sql extension\n",
        "%load_ext sql"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3) Configuration â€” repo & DB paths (pre-filled)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === EDIT ONLY IF NEEDED ===\n",
        "GITHUB_USER   = \"danielgraves\"\n",
        "GITHUB_REPO   = \"Graves_Greenery_Analysis\"\n",
        "GITHUB_BRANCH = \"main\"\n",
        "CSV_GLOB      = \"data/**/*.csv\"   # recursive search under /data/\n",
        "DB_PATH       = \"/content/graves_greenery.duckdb\"\n",
        "REPO_DIR      = f\"/content/{GITHUB_REPO}\"\n",
        "INCLUDE_PARENT_IN_TABLE = False"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4) Start DuckDB (file-backed) and connect `%%sql`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Path(DB_PATH).parent.mkdir(parents=True, exist_ok=True)\n",
        "%sql duckdb:///{DB_PATH}\n",
        "print('Connected to DuckDB at', DB_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5) Clone (or Pull) your GitHub repo (public)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clone_or_pull_repo(user, repo, branch, dest):\n",
        "    if os.path.exists(dest):\n",
        "        print(f'Repo exists at {dest}. Pulling latest...')\n",
        "        subprocess.run(f'git -C {dest} pull --ff-only', shell=True, check=True)\n",
        "        return\n",
        "    cmd = f'git clone --depth 1 --branch {branch} https://github.com/{user}/{repo}.git {dest}'\n",
        "    print(cmd)\n",
        "    subprocess.run(cmd, shell=True, check=True)\n",
        "\n",
        "clone_or_pull_repo(GITHUB_USER, GITHUB_REPO, GITHUB_BRANCH, REPO_DIR)\n",
        "print('Repo ready at:', REPO_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6) Load CSVs into DuckDB tables (Option A â€” SQLAlchemy engine)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sqlalchemy import create_engine\n",
        "engine = create_engine(f'duckdb:///{DB_PATH}')\n",
        "\n",
        "def slugify_table_name(path, include_parent=False):\n",
        "    path = Path(path)\n",
        "    stem = re.sub(r'[^a-z0-9_]+', '_', path.stem.lower()).strip('_')\n",
        "    if include_parent and path.parent != path.parent.parent:\n",
        "        parent = re.sub(r'[^a-z0-9_]+', '_', path.parent.name.lower()).strip('_')\n",
        "        name = f\"{parent}_{stem}\"\n",
        "    else:\n",
        "        name = stem\n",
        "    if re.match(r'^\\d', name):\n",
        "        name = 't_' + name\n",
        "    return name\n",
        "\n",
        "def load_csvs_as_tables(repo_dir, csv_glob, include_parent=False):\n",
        "    csvs = glob.glob(os.path.join(repo_dir, csv_glob), recursive=True)\n",
        "    loaded = []\n",
        "    with engine.begin() as conn:\n",
        "        for f in csvs:\n",
        "            tbl = slugify_table_name(f, include_parent=include_parent)\n",
        "            conn.exec_driver_sql(\n",
        "                f\"\"\"\n",
        "                CREATE OR REPLACE TABLE \"{tbl}\" AS\n",
        "                SELECT * FROM read_csv_auto(?, header=True, sample_size=-1, ignore_errors=True);\n",
        "                \"\"\",\n",
        "                (f,)\n",
        "            )\n",
        "            loaded.append((tbl, f))\n",
        "    return loaded\n",
        "\n",
        "loaded = load_csvs_as_tables(REPO_DIR, CSV_GLOB, INCLUDE_PARENT_IN_TABLE)\n",
        "print(f'Loaded {len(loaded)} CSVs into DuckDB tables.')\n",
        "loaded[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7) Verify: list available tables"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\n",
        "SELECT table_name\n",
        "FROM duckdb_tables()\n",
        "WHERE NOT internal\n",
        "ORDER BY table_name;"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8) Test query"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\n",
        "SELECT * FROM dim_customers LIMIT 5;"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9) (Optional) `%%mysql` magic â€” write MySQL syntax via SQLGlot"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sqlglot import transpile\n",
        "from IPython.core.magic import register_cell_magic\n",
        "\n",
        "@register_cell_magic\n",
        "def mysql(line, cell):\n",
        "    [duckdb_sql] = transpile(cell, read='mysql', write='duckdb')\n",
        "    duckdb_sql = duckdb_sql.replace('IFNULL', 'COALESCE').replace('NOW()', 'CURRENT_TIMESTAMP')\n",
        "    print('Translated to DuckDB SQL:\\n', duckdb_sql, '\\n', flush=True)\n",
        "    return get_ipython().run_cell_magic('sql', '', duckdb_sql)\n",
        "\n",
        "print('Custom %%mysql magic is ready.')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10) Refresh data (git pull + reload CSVs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "subprocess.run(f'git -C {REPO_DIR} pull --ff-only', shell=True, check=True)\n",
        "loaded = load_csvs_as_tables(REPO_DIR, CSV_GLOB, INCLUDE_PARENT_IN_TABLE)\n",
        "print(f'Reloaded {len(loaded)} CSVs into DuckDB tables.')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11) Snapshot / export"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('DuckDB snapshot at:', DB_PATH)\n",
        "export_path = '/content/sample_export.csv'\n",
        "_ = get_ipython().run_cell_magic('sql', '', textwrap.dedent(f\"\"\"\n",
        "COPY (SELECT * FROM dim_customers LIMIT 10)\n",
        "TO '{export_path}' WITH (HEADER, DELIMITER ',');\n",
        "\"\"\"))\n",
        "print('Exported CSV:', export_path)"
      ]
    }
  ],
  "metadata": {},
  "nbformat": 4,
  "nbformat_minor": 5
}
