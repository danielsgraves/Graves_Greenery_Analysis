{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bd893f1"
      },
      "source": [
        "# ðŸŒ¿ Graves Greenery â€” Colab SQL Template (DuckDB + `%%sql` + GitHub CSVs)\n",
        "\n",
        "A serverless SQL sandbox for the Graves Greenery project.\n",
        "\n",
        "- Loads CSVs from your GitHub repo (public)\n",
        "- Creates tables in a persistent DuckDB database\n",
        "- Enables `%%sql` magic for pretty outputs\n",
        "- Optional `%%mysql` magic to use MySQL syntax via SQLGlot\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2a7a7a3"
      },
      "source": [
        "## 1) Install packages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5c5e5b1"
      },
      "outputs": [],
      "source": [
        "!pip -q install duckdb ipython-sql pandas duckdb-engine sqlalchemy sqlglot\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8a6f3fa"
      },
      "source": [
        "## 2) Imports & load SQL magic\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4b8f4a74"
      },
      "outputs": [],
      "source": [
        "import os, re, glob, subprocess, textwrap, pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "# Load the ipython-sql extension\n",
        "%load_ext sql\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cbe3b80"
      },
      "source": [
        "## 3) Configuration â€” repo & DB paths (pre-filled)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2e5d873b"
      },
      "outputs": [],
      "source": [
        "# === EDIT ONLY IF NEEDED ===\n",
        "GITHUB_USER   = \"danielgraves\"\n",
        "GITHUB_REPO   = \"Graves_Greenery_Analysis\"\n",
        "GITHUB_BRANCH = \"main\"\n",
        "CSV_GLOB      = \"data/**/*.csv\"   # recursive search under /data/\n",
        "DB_PATH       = \"/content/graves_greenery.duckdb\"\n",
        "REPO_DIR      = f\"/content/{GITHUB_REPO}\"\n",
        "INCLUDE_PARENT_IN_TABLE = False\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1b3f2c21"
      },
      "source": [
        "## 4) Start DuckDB (file-backed) and connect `%%sql`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aa62c4d9"
      },
      "outputs": [],
      "source": [
        "Path(DB_PATH).parent.mkdir(parents=True, exist_ok=True)\n",
        "%sql duckdb:///{DB_PATH}\n",
        "print('Connected to DuckDB at', DB_PATH)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3f7f01a0"
      },
      "source": [
        "## 5) Clone (or Pull) your GitHub repo (public)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eaac5bb7"
      },
      "outputs": [],
      "source": [
        "def clone_or_pull_repo(user, repo, branch, dest):\n",
        "    if os.path.exists(dest):\n",
        "        print(f'Repo exists at {dest}. Pulling latest...')\n",
        "        subprocess.run(f'git -C {dest} pull --ff-only', shell=True, check=True)\n",
        "        return\n",
        "    cmd = f'git clone --depth 1 --branch {branch} https://github.com/{user}/{repo}.git {dest}'\n",
        "    print(cmd)\n",
        "    subprocess.run(cmd, shell=True, check=True)\n",
        "\n",
        "clone_or_pull_repo(GITHUB_USER, GITHUB_REPO, GITHUB_BRANCH, REPO_DIR)\n",
        "print('Repo ready at:', REPO_DIR)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2a5c840a"
      },
      "source": [
        "## 6) Load CSVs into DuckDB tables (Option A â€” SQLAlchemy engine)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0d20a99"
      },
      "outputs": [],
      "source": [
        "from sqlalchemy import create_engine\n",
        "engine = create_engine(f'duckdb:///{DB_PATH}')\n",
        "\n",
        "def slugify_table_name(path, include_parent=False):\n",
        "    path = Path(path)\n",
        "    stem = re.sub(r'[^a-z0-9_]+', '_', path.stem.lower()).strip('_')\n",
        "    if include_parent and path.parent != path.parent.parent:\n",
        "        parent = re.sub(r'[^a-z0-9_]+', '_', path.parent.name.lower()).strip('_')\n",
        "        name = f\"{parent}_{stem}\"\n",
        "    else:\n",
        "        name = stem\n",
        "    if re.match(r'^\\\\d', name):\n",
        "        name = 't_' + name\n",
        "    return name\n",
        "\n",
        "def load_csvs_as_tables(repo_dir, csv_glob, include_parent=False):\n",
        "    csvs = glob.glob(os.path.join(repo_dir, csv_glob), recursive=True)\n",
        "    loaded = []\n",
        "    with engine.begin() as conn:\n",
        "        for f in csvs:\n",
        "            tbl = slugify_table_name(f, include_parent=include_parent)\n",
        "            conn.exec_driver_sql(\n",
        "                f\"\"\"\n",
        "                CREATE OR REPLACE TABLE \"{tbl}\" AS\n",
        "                SELECT * FROM read_csv_auto(?, header=True, sample_size=-1, ignore_errors=True);\n",
        "                \"\"\",\n",
        "                (f,)\n",
        "            )\n",
        "            loaded.append((tbl, f))\n",
        "    return loaded\n",
        "\n",
        "loaded = load_csvs_as_tables(REPO_DIR, CSV_GLOB, INCLUDE_PARENT_IN_TABLE)\n",
        "print(f'Loaded {len(loaded)} CSVs into DuckDB tables.')\n",
        "loaded[:10]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1f3f7d2"
      },
      "source": [
        "## 7) Verify: list available tables\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8d2d30d1"
      },
      "outputs": [],
      "source": [
        "%%sql\n",
        "SELECT table_name\n",
        "FROM duckdb_tables()\n",
        "WHERE NOT internal\n",
        "ORDER BY table_name;\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6c2bf4e"
      },
      "source": [
        "## 8) Test query\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b902a6a0"
      },
      "outputs": [],
      "source": [
        "%%sql\n",
        "SELECT * FROM dim_customers LIMIT 5;\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a4a6f59"
      },
      "source": [
        "## 9) (Optional) `%%mysql` magic â€” write MySQL syntax via SQLGlot\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5c9b9f6"
      },
      "outputs": [],
      "source": [
        "from sqlglot import transpile\n",
        "from IPython.core.magic import register_cell_magic\n",
        "\n",
        "@register_cell_magic\n",
        "def mysql(line, cell):\n",
        "    [duckdb_sql] = transpile(cell, read='mysql', write='duckdb')\n",
        "    duckdb_sql = duckdb_sql.replace('IFNULL', 'COALESCE').replace('NOW()', 'CURRENT_TIMESTAMP')\n",
        "    print('Translated to DuckDB SQL:\\n', duckdb_sql, '\\n', flush=True)\n",
        "    return get_ipython().run_cell_magic('sql', '', duckdb_sql)\n",
        "\n",
        "print('Custom %%mysql magic is ready.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fce8d43"
      },
      "source": [
        "## 10) Refresh data (git pull + reload CSVs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2a9cd3b"
      },
      "outputs": [],
      "source": [
        "subprocess.run(f'git -C {REPO_DIR} pull --ff-only', shell=True, check=True)\n",
        "loaded = load_csvs_as_tables(REPO_DIR, CSV_GLOB, INCLUDE_PARENT_IN_TABLE)\n",
        "print(f'Reloaded {len(loaded)} CSVs into DuckDB tables.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6b3f2a88"
      },
      "source": [
        "## 11) Snapshot / export\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b9fdf1a0"
      },
      "outputs": [],
      "source": [
        "print('DuckDB snapshot at:', DB_PATH)\n",
        "export_path = '/content/sample_export.csv'\n",
        "_ = get_ipython().run_cell_magic('sql', '', textwrap.dedent(f\"\"\"\n",
        "COPY (SELECT * FROM dim_customers LIMIT 10)\n",
        "TO '{export_path}' WITH (HEADER, DELIMITER ',');\n",
        "\"\"\"))\n",
        "print('Exported CSV:', export_path)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Graves_Greenery_Colab_Template.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
